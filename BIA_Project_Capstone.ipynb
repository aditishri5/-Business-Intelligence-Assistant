{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbd7667-0da4-4ade-aa1e-ee511b3e7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community\n",
    "#!pip install --upgrade langchain\n",
    "#!pip show langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09439a6-34a8-4cf0-b0d7-a5553ed9c324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Customer_Gender</th>\n",
       "      <th>Customer_Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>Widget C</td>\n",
       "      <td>South</td>\n",
       "      <td>786</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.874407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>Widget D</td>\n",
       "      <td>East</td>\n",
       "      <td>850</td>\n",
       "      <td>29</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.365205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>Widget A</td>\n",
       "      <td>North</td>\n",
       "      <td>871</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.547364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>Widget C</td>\n",
       "      <td>South</td>\n",
       "      <td>464</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.555420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>Widget C</td>\n",
       "      <td>South</td>\n",
       "      <td>262</td>\n",
       "      <td>50</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.982935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Product Region  Sales  Customer_Age Customer_Gender  \\\n",
       "0  2022-01-01  Widget C  South    786            26            Male   \n",
       "1  2022-01-02  Widget D   East    850            29            Male   \n",
       "2  2022-01-03  Widget A  North    871            40          Female   \n",
       "3  2022-01-04  Widget C  South    464            31            Male   \n",
       "4  2022-01-05  Widget C  South    262            50          Female   \n",
       "\n",
       "   Customer_Satisfaction  \n",
       "0               2.874407  \n",
       "1               3.365205  \n",
       "2               4.547364  \n",
       "3               4.555420  \n",
       "4               3.982935  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "#Using PyPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_paths =[ \"AI business model innovation.pdf\",\n",
    "            \"BI approaches.pdf\",\n",
    "            \"Time-Series-Data-Prediction-using-IoT-and-Machine-Le_2020_Procedia-Computer-.pdf\",\n",
    "            \"Walmarts sales data analysis.pdf\"\n",
    "]\n",
    "\n",
    "# Load and combine all PDF documents\n",
    "all_docs = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    all_docs.extend(loader.load())\n",
    "\n",
    "# PDF Implementation: text splitter for pdfs\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(all_docs)\n",
    "\n",
    "   \n",
    "    \n",
    "#load CSV File\n",
    "Sales_data_csv = pd.read_csv('sales_data.csv')\n",
    "# Preview the CSV File\n",
    "Sales_data_csv.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61dd0288-4bf7-4af1-9e82-201c5fc86f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: In January 2022, the sales performance varied across different products and regions. Here is a summary of the sales data for the month:\n",
      "\n",
      "1. Widget A:\n",
      "   - Sales: 871 (North)\n",
      "   - Sales: 936 (South)\n",
      "\n",
      "2. Widget B:\n",
      "   - Sales: 542 (North)\n",
      "\n",
      "3. Widget C:\n",
      "   - Sales: 422 (North)\n",
      "\n",
      "Based on the data provided, Widget A had the highest sales in January, with 936 units sold in the South region. Widget B and Widget C had lower sales compared to Widget A. The North region had sales for all three products, with Widget A having the highest sales in that region.\n",
      "\n",
      "Overall, the sales performance in January 2022 was relatively good, with Widget A being the top-selling product, especially in the South region.\n",
      "Answer 2: To create customer segmentation by region, we can analyze the data provided for the North region. Based on the information given, we can segment customers in the North region by their characteristics such as age, gender, sales, and satisfaction level. Here is a breakdown of the customer segmentation for the North region:\n",
      "\n",
      "1. Age Group:\n",
      "   - Young Customers (Age < 30): 2 customers\n",
      "   - Middle-aged Customers (30 <= Age <= 60): 2 customers\n",
      "\n",
      "2. Gender:\n",
      "   - Male Customers: 2 customers\n",
      "   - Female Customers: 2 customers\n",
      "\n",
      "3. Sales:\n",
      "   - Low Sales (< 400): 1 customer\n",
      "   - Medium Sales (400 <= Sales <= 600): 2 customers\n",
      "   - High Sales (> 600): 1 customer\n",
      "\n",
      "4. Customer Satisfaction:\n",
      "   - Low Satisfaction (< 2.5): 1 customer\n",
      "   - Medium Satisfaction (2.5 <= Satisfaction <= 4.5): 3 customers\n",
      "\n",
      "This segmentation provides an overview of the customers in the North region based on their age, gender, sales, and satisfaction levels. It can help in understanding the different customer profiles within the region and tailoring marketing strategies or product offerings accordingly.\n",
      "Answer 3: Some statistical measures that can be applied to the data mentioned in the context include:\n",
      "\n",
      "1. Mean: Calculating the average value of a set of data points can help in understanding the central tendency of the data. For example, mean values of parameters like temperature, fuel price, holidays, unemployment rate, and store sales can provide insights into their typical values.\n",
      "\n",
      "2. Regression Analysis: Using regression models to find relationships between variables like temperature, fuel price, holidays, unemployment rate, and store sales can help in predicting future sales and identifying trends in the data.\n",
      "\n",
      "3. Correlation Analysis: Examining the correlation between variables such as temperature, fuel price, holidays, unemployment rate, and store sales can provide insights into how these factors are related to each other and impact sales.\n",
      "\n",
      "4. Forecasting: Utilizing forecasting techniques to predict future sales based on historical data and trends observed in the dataset.\n",
      "\n",
      "5. Data Visualization: Visualizing the data using tools like GraphX library provided by Apache Spark can help in identifying relationships between values, trends, and patterns in the data.\n",
      "\n",
      "These statistical measures can assist in analyzing the data, identifying patterns, making predictions, and optimizing decision-making processes in the enterprise environment.\n",
      "Answer 4: The technology implementation of Walmart includes the use of Apache Spark for analyzing sales data and its relationship with factors such as temperature, fuel price, unemployment rate, and holidays. Apache Spark is used along with various libraries to process and analyze the dataset containing weekly sales data from 45 Walmart stores with 99 departments each. Additionally, Walmart utilizes Big Data technologies like MapReduce with Hadoop to gain valuable insights into customer behaviors, business trends, and sales forecasting.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "#load and process csv data\n",
    "loader = CSVLoader(file_path='sales_data.csv')\n",
    "docs = loader.load_and_split()\n",
    "\n",
    "#Initiate faiss vector store and openai embedding\n",
    "embeddings = OpenAIEmbeddings()\n",
    "index = faiss.IndexFlatL2(len(OpenAIEmbeddings().embed_query(\" \")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "\n",
    "# Add pdf docs to the vector store\n",
    "vector_store = FAISS.from_documents(split_docs, embedding=embeddings) \n",
    "\n",
    "#splitted csv data to the vector store\n",
    "vector_store.add_documents(documents=docs)\n",
    "\n",
    "#Create the retrieval chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Set up system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    \n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# 3. Create a history-aware retriever\n",
    "history_aware_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    prompt=history_aware_prompt\n",
    ")\n",
    "\n",
    "# 4. Create the document QA chain (combine retrieved docs + question)\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Use the context to answer the question.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"system\", \"Context:\\n{context}\")\n",
    "])\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "# 5. Create the final retrieval chain\n",
    "retrieval_chain = create_retrieval_chain(history_aware_retriever, combine_docs_chain)\n",
    "\n",
    "# 6. Memory wrapper to handle chat history\n",
    "message_histories = {}  # Store for multiple session histories\n",
    "\n",
    "# 6. Wrap the chain to ensure output is under \"output\" key (to avoid KeyError)\n",
    "wrapped_chain = retrieval_chain | RunnableLambda(lambda x: {\"output\": x[\"answer\"]})\n",
    "\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    wrapped_chain,\n",
    "    lambda session_id: InMemoryChatMessageHistory(),  # Use simple in-memory store\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# 7. Simulate a conversation\n",
    "session_id = \"user-123\"\n",
    "\n",
    "#Query the rag bot with a question based on the CSV data\n",
    "\n",
    "response1 = chain_with_memory.invoke({\"input\": \"Analyze the sales performance of January 2022?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "print(\"Answer 1:\", response1[\"output\"])\n",
    "\n",
    "response2 = chain_with_memory.invoke({\"input\": \"Create Customer Segmentation by Region?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "print(\"Answer 2:\", response2[\"output\"])\n",
    "\n",
    "response3 = chain_with_memory.invoke({\"input\": \"Create Statistical Measures for this data?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "print(\"Answer 3:\", response3[\"output\"])\n",
    "\n",
    "#Query the rag bot with a question based on pdf\n",
    "response4 = chain_with_memory.invoke({\"input\": \"What Are The Technology Implementation of walmart?\"}, config={\"configurable\": {\"session_id\": session_id}})\n",
    "print(\"Answer 4:\", response4[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954c349-b5c8-4471-b07e-559371de4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QA Evaluation for model performance and accuracy\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "\n",
    "# Step 1: Instantiate the evaluation chain\n",
    "qa_eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "# Step 2: Define ground truth examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Which was the best-selling product in January 2022 ?\",\n",
    "        \"answer\": \"In January 2022, Widget A was the best-selling product\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the Median Customer Age in the given data?\",\n",
    "        \"answer\": \"Median Customer Age is 40.5\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the range of sales?\",\n",
    "        \"answer\": \"Range of Sales is 569\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 3: Collect the model's predicted responses\n",
    "predictions = [\n",
    "    {\"result\": response1[\"output\"]},\n",
    "    {\"result\": response2[\"output\"]},\n",
    "    {\"result\": response3[\"output\"]}\n",
    "]\n",
    "\n",
    "# Step 4: Run evaluation\n",
    "eval_results = qa_eval_chain.evaluate(\n",
    "    examples=examples,\n",
    "    predictions=predictions,\n",
    "    question_key=\"query\",\n",
    "    answer_key=\"answer\",\n",
    "    prediction_key=\"result\"\n",
    ")\n",
    "    \n",
    "# Step 5: Display evaluation results\n",
    "for i, result in enumerate(eval_results):\n",
    "    print(f\"\\n[Q{i+1}] {examples[i]['query']}\")\n",
    "    print(f\"Prediction: {predictions[i]['result']}\")\n",
    "    print(f\"Expected: {examples[i]['answer']}\")\n",
    "    print(f\"Feedback: {result['results']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
